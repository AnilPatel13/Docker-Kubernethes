# 4-node Kubernetes lab (kubeadm + containerd + Calico)
# Nodes: k8s-master, k8s-worker1, k8s-worker2, k8s-client (kubectl)
VAGRANT_BOX = "ubuntu/focal64"
CPU = 4
RAM = 6144
POD_CIDR = "192.168.0.0/16"    # Calico default
MASTER_IP = "192.168.56.10"
WORKER1_IP = "192.168.56.11"
WORKER2_IP = "192.168.56.12"
CLIENT_IP  = "192.168.56.13"

COMMON_SH = <<-SHELL
  set -euxo pipefail

  # --- Basics ---
  sudo apt-get update -y
  sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release software-properties-common

  # --- Disable swap (Kubernetes requirement) ---
  sudo swapoff -a
  sudo sed -ri '/\\sswap\\s/s/^#?/#/' /etc/fstab

  # --- Kernel modules & sysctl for Kubernetes networking ---
  cat <<'EOF' | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF
  sudo modprobe overlay
  sudo modprobe br_netfilter

  cat <<'EOF' | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
  sudo sysctl --system

  # --- Install containerd (from Docker repo) ---
  install -m 0755 -d /etc/apt/keyrings
  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor | sudo tee /etc/apt/keyrings/docker.gpg >/dev/null
  echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list >/dev/null
  sudo apt-get update -y
  sudo apt-get install -y containerd.io

  # --- Explicit containerd config with CRI enabled + systemd cgroup ---
  sudo mkdir -p /etc/containerd
  cat <<'EOF' | sudo tee /etc/containerd/config.toml
version = 2

[plugins]
  [plugins."io.containerd.grpc.v1.cri"]
    sandbox_image = "registry.k8s.io/pause:3.9"
    [plugins."io.containerd.grpc.v1.cri".containerd]
      default_runtime_name = "runc"
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
      runtime_type = "io.containerd.runc.v2"
      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
        SystemdCgroup = true
EOF

  # Make sure CRI is NOT disabled
  sudo sed -i '/^disabled_plugins\\s*=\\s*\\[/d' /etc/containerd/config.toml

  sudo systemctl daemon-reload
  sudo systemctl enable --now containerd
  sudo systemctl restart containerd

  # --- crictl points to containerd socket (handy for debugging) ---
  cat <<'EOF' | sudo tee /etc/crictl.yaml
runtime-endpoint: unix:///var/run/containerd/containerd.sock
image-endpoint: unix:///var/run/containerd/containerd.sock
timeout: 10
debug: false
EOF

  # --- Kubernetes apt repo (stable 1.30 stream for Ubuntu 20.04) ---
  sudo mkdir -p /etc/apt/keyrings
  curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
  echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

  sudo apt-get update -y
  sudo apt-get install -y kubelet kubeadm kubectl
  sudo apt-mark hold kubelet kubeadm kubectl
SHELL

MASTER_SH = <<-SHELL
  set -euxo pipefail

  # Wait for containerd CRI to be ready
  for i in {1..30}; do
    if sudo crictl info >/dev/null 2>&1; then
      break
    fi
    echo "Waiting for containerd CRI..."
    sleep 2
  done

  # Initialize the control plane
  sudo kubeadm init --apiserver-advertise-address=#{MASTER_IP} --pod-network-cidr=#{POD_CIDR} --cri-socket=unix:///var/run/containerd/containerd.sock

  # Configure kubectl for vagrant user
  sudo -u vagrant -H mkdir -p /home/vagrant/.kube
  sudo cp -i /etc/kubernetes/admin.conf /home/vagrant/.kube/config
  sudo chown vagrant:vagrant /home/vagrant/.kube/config

  # Save admin.conf to the shared folder (for client node)
  sudo cp -f /etc/kubernetes/admin.conf /vagrant/admin.conf
  sudo chown vagrant:vagrant /vagrant/admin.conf

  # Install Calico CNI
  sudo -u vagrant -H bash -lc "kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.3/manifests/calico.yaml"

  # Create worker join script
  sudo kubeadm token create --print-join-command --ttl 24h > /vagrant/join.sh
  sudo chmod +x /vagrant/join.sh

  # Best-effort: wait for master node ready
  sudo -u vagrant -H bash -lc "kubectl wait --for=condition=Ready nodes --all --timeout=180s || true"
SHELL

WORKER_SH = <<-SHELL
  set -euxo pipefail

  # Wait until join.sh appears from master
  for i in {1..60}; do
    if [ -f /vagrant/join.sh ]; then
      break
    fi
    echo "Waiting for /vagrant/join.sh ..."
    sleep 5
  done

  if [ ! -f /vagrant/join.sh ]; then
    echo "join.sh not found after waiting â€” aborting."
    exit 1
  fi

  # Ensure containerd CRI is up
  for i in {1..30}; do
    if sudo crictl info >/dev/null 2>&1; then
      break
    fi
    echo "Waiting for containerd CRI..."
    sleep 2
  done

  sudo bash /vagrant/join.sh --cri-socket=unix:///var/run/containerd/containerd.sock
SHELL

CLIENT_SH = <<-SHELL
  set -euxo pipefail

  # Use kubeconfig from shared folder
  mkdir -p /home/vagrant/.kube
  cp /vagrant/admin.conf /home/vagrant/.kube/config
  chown -R vagrant:vagrant /home/vagrant/.kube

  # Quick test
  sudo -u vagrant -H bash -lc "kubectl get nodes -o wide || true"
SHELL

Vagrant.configure("2") do |config|
  config.vm.box = VAGRANT_BOX

  # k8s-master
  config.vm.define "k8s-master" do |node|
    node.vm.hostname = "k8s-master"
    node.vm.network "private_network", ip: MASTER_IP
    node.vm.provider "virtualbox" do |vb|
      vb.cpus = CPU
      vb.memory = RAM
    end
    node.vm.provision "shell", inline: COMMON_SH
    node.vm.provision "shell", inline: MASTER_SH
  end

  # k8s-worker1
  config.vm.define "k8s-worker1" do |node|
    node.vm.hostname = "k8s-worker1"
    node.vm.network "private_network", ip: WORKER1_IP
    node.vm.provider "virtualbox" do |vb|
      vb.cpus = CPU
      vb.memory = RAM
    end
    node.vm.provision "shell", inline: COMMON_SH
    node.vm.provision "shell", inline: WORKER_SH
  end

  # k8s-worker2
  config.vm.define "k8s-worker2" do |node|
    node.vm.hostname = "k8s-worker2"
    node.vm.network "private_network", ip: WORKER2_IP
    node.vm.provider "virtualbox" do |vb|
      vb.cpus = CPU
      vb.memory = RAM
    end
    node.vm.provision "shell", inline: COMMON_SH
    node.vm.provision "shell", inline: WORKER_SH
  end

  # k8s-client (kubectl)
  config.vm.define "k8s-client" do |node|
    node.vm.hostname = "k8s-client"
    node.vm.network "private_network", ip: CLIENT_IP
    node.vm.provider "virtualbox" do |vb|
      vb.cpus = CPU
      vb.memory = RAM
    end
    node.vm.provision "shell", inline: COMMON_SH
    node.vm.provision "shell", inline: CLIENT_SH
  end
end
